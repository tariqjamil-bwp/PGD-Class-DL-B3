{"cells":[{"cell_type":"markdown","metadata":{"id":"qQGgSiQ4mlFf"},"source":["## **1. Packages & Liberaries**\n","### *1a. Import of Packages*"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":56028,"status":"ok","timestamp":1700927761798,"user":{"displayName":"TARIQ JAMIL","userId":"15811585553781902842"},"user_tz":-300},"id":"X1_ZV10ml68e","colab":{"base_uri":"https://localhost:8080/"},"outputId":"150a0691-ae65-40e8-c4da-5c8cf81213ed"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[31mERROR: Invalid requirement: 'langchain,'\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip install -q -U bitsandbytes\n","!pip install -q -U transformers\n","!pip install -q -U accelerate\n","!pip install -q -U einops\n","!pip install -q langchain, gradio"]},{"cell_type":"markdown","metadata":{"id":"SryqQp38mupa"},"source":["### *1b. Import of Packages*"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":5100,"status":"ok","timestamp":1700927766894,"user":{"displayName":"TARIQ JAMIL","userId":"15811585553781902842"},"user_tz":-300},"id":"pGEYi2Oyl0uM"},"outputs":[],"source":["from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n","import torch"]},{"cell_type":"markdown","metadata":{"id":"5262gWFmm05B"},"source":["## **2. Model Definitions**\n","### *2a. Model Selection & some initializations*"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1700927766895,"user":{"displayName":"TARIQ JAMIL","userId":"15811585553781902842"},"user_tz":-300},"id":"a_ksYpiXrDS8"},"outputs":[],"source":["base_model_id = 'HuggingFaceH4/zephyr-7b-beta'"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1700927766896,"user":{"displayName":"TARIQ JAMIL","userId":"15811585553781902842"},"user_tz":-300},"id":"9AVwm2mol0uO","outputId":"0e6e9e7a-f3df-4e4c-8b70-3ced54866060"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.float16 cuda:0\n"]}],"source":["compute_dtype = getattr(torch, \"float16\")\n","dtype = torch.bfloat16 if torch.cuda.get_device_capability()[0] == 8 else compute_dtype\n","DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n","\n","print(dtype, DEVICE)"]},{"cell_type":"markdown","metadata":{"id":"T63yeudGnp7v"},"source":["### *2b. Model Configuration Settings*"]},{"cell_type":"markdown","metadata":{"id":"oiKi4imEoqG3"},"source":["### *2b. Model & tokenizer Instantiation*\n","\n","1.   I didn't use bitsandbytes, / bnb_configuration as model size is already too less."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["292d239d700a43c4959cbb8734c0fd33","4ad380a5cc0c491cbbe7f082c6955aa5","d2936272d6dc4cc68e0991dd0708c0bb","e4b04c088d4547cf90f8139f5690b386","7d67ea40bfd24a3ea40be7f346164808","879d5bc6beed45819c2a8a9bead9efc2","93418527ad52431cb052cb41511f3f05","29469c80c2fb4de284abbc59efc797d3","91c36238ef0c42f6a9b37074f419d85c","a2b051e09bc94e7f90ffbca590b4a866","2f1c27d7ad694026808538d5af3cf254"]},"executionInfo":{"elapsed":87136,"status":"ok","timestamp":1700927854018,"user":{"displayName":"TARIQ JAMIL","userId":"15811585553781902842"},"user_tz":-300},"id":"udnrxCVql0uO","outputId":"ab71e911-06c6-461b-88fd-d8a5ac159ec5"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"292d239d700a43c4959cbb8734c0fd33"}},"metadata":{}}],"source":["model = AutoModelForCausalLM.from_pretrained(\n","          base_model_id,\n","          trust_remote_code=True,\n","          load_in_8bit=True,\n","          torch_dtype = dtype,\n","          device_map=\"auto\"\n","          )\n","\n","tokenizer = AutoTokenizer.from_pretrained(base_model_id, use_fast=True, padding_side='left')"]},{"cell_type":"markdown","metadata":{"id":"wNT6dEbEw4vR"},"source":["### *2c. Setting up Text Generation Config*"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1700927854019,"user":{"displayName":"TARIQ JAMIL","userId":"15811585553781902842"},"user_tz":-300},"id":"VtAJ1XFVw4VV"},"outputs":[],"source":["from transformers import GenerationConfig, TextStreamer\n","\n","text_generation_config = GenerationConfig(\n","    temperature = 0.1,\n","    max_new_tokens = 128,\n","    repetition_penalty = 1.7,\n","    num_return_sequences = 1,\n","    do_sample = True,\n","    pad_token_id = tokenizer.eos_token_id,\n","    eos_token_id = tokenizer.eos_token_id,\n",")\n","\n","streamer = TextStreamer(\n","    tokenizer, skip_prompt=True, skip_special_tokens=True, use_multiprocessing=False)"]},{"cell_type":"code","source":["from transformers.generation.utils import StoppingCriteria, StoppingCriteriaList, List\n","\n","class StopGenerationCriteria(StoppingCriteria):\n","    def __init__(self, tokens: List[List[str]], tokenizer: AutoTokenizer, device: torch.device):\n","\n","        stop_token_ids = [tokenizer.convert_tokens_to_ids(t) for t in tokens]\n","        self.stop_token_ids = [\n","            torch.tensor(x, dtype=torch.long, device=device) for x in stop_token_ids]\n","\n","    def __call__(\n","        self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n","        for stop_ids in self.stop_token_ids:\n","            if torch.eq(input_ids[0][-len(stop_ids) :], stop_ids).all():\n","                return True\n","        return False\n","\n","stop_tokens = [[\"<|\"]]\n","stopping_criteria = StoppingCriteriaList(\n","    [StopGenerationCriteria(stop_tokens, tokenizer, model.device)])"],"metadata":{"id":"SlOdJ6uUyBxx","executionInfo":{"status":"ok","timestamp":1700927854019,"user_tz":-300,"elapsed":19,"user":{"displayName":"TARIQ JAMIL","userId":"15811585553781902842"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PnYyqw1CtrAx"},"source":["### *2d. Checking model / tokenizer loading"]},{"cell_type":"code","execution_count":8,"metadata":{"cellView":"form","executionInfo":{"elapsed":17,"status":"ok","timestamp":1700927854019,"user":{"displayName":"TARIQ JAMIL","userId":"15811585553781902842"},"user_tz":-300},"id":"6EicVFEQzhaC"},"outputs":[],"source":["# @title\n","#magic code to enable text-wrap in google colab\n","from IPython.display import HTML, display\n","\n","def set_css():\n","  display(HTML('''\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  '''))\n","get_ipython().events.register('pre_run_cell', set_css)"]},{"cell_type":"markdown","metadata":{"id":"6LAGcpC0usIZ"},"source":["## 3. **Inference Pipelines**"]},{"cell_type":"markdown","metadata":{"id":"8MZ3_rxh5J-d"},"source":["### *3b. Inference Pipeline*"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":7013,"status":"ok","timestamp":1700927861015,"user":{"displayName":"TARIQ JAMIL","userId":"15811585553781902842"},"user_tz":-300},"id":"ehNH2N2U1hj2","outputId":"926e6757-e055-493d-d40d-0b5e27c3ecfb"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["from transformers import pipeline\n","from langchain import HuggingFacePipeline\n","\n","pipe = pipeline(\n","    \"text-generation\",\n","    model = model,\n","    tokenizer = tokenizer,\n","    do_sample=True,\n","    generation_config=text_generation_config,\n","    streamer=streamer,\n","    stopping_criteria = stopping_criteria,\n","    batch_size=1,\n",")\n","\n","llm = HuggingFacePipeline(pipeline = pipe)"]},{"cell_type":"code","execution_count":10,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1700927861016,"user":{"displayName":"TARIQ JAMIL","userId":"15811585553781902842"},"user_tz":-300},"id":"0DSgtVjacRPg","outputId":"8c9392e9-e825-4b4e-f789-365505a6f45d"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["# @title\n","# this code is to suppress package loading once it is done in between the code.\n","import locale\n","def getpreferredencoding(do_setlocale = True):\n","    return \"UTF-8\"\n","locale.getpreferredencoding = getpreferredencoding\n","\n","# just suppress unwanted warnings\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=UserWarning)"]},{"cell_type":"code","source":["!pip3 install -qqq chromadb\n","!pip3 install -qqq sentence_transformers pypdf"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"5uQv3G65BjpF","executionInfo":{"status":"ok","timestamp":1700927874357,"user_tz":-300,"elapsed":13363,"user":{"displayName":"TARIQ JAMIL","userId":"15811585553781902842"}},"outputId":"aafef58f-2c8b-46a9-feb3-49125b999d7d"},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"Ce8T_8t6UseY"},"source":["### LANGCHAIN: an essential for conversation bots"]},{"cell_type":"code","source":["# Imports\n","#from chromadb.config import Settings\n","import numpy as np\n","import chromadb\n","import os # operating system dependent functionality, to walk through directories and files\n","\n","from chromadb.utils import embedding_functions # loads Chroma's embedding functions from OpenAI, HuggingFace, SentenceTransformer and others\n","from langchain.vectorstores import Chroma # wrapper around ChromaDB embeddings platform\n","from langchain.text_splitter import RecursiveCharacterTextSplitter # recursively tries to split by different characters to find one that works\n","from langchain.chains.question_answering import load_qa_chain\n","from langchain.document_loaders import PyPDFDirectoryLoader\n","from langchain.embeddings import HuggingFaceEmbeddings\n","from langchain.chains import LLMChain, RetrievalQA, RetrievalQAWithSourcesChain\n","from langchain.prompts import PromptTemplate"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"5k90z-d8BtW1","executionInfo":{"status":"ok","timestamp":1700927876862,"user_tz":-300,"elapsed":2565,"user":{"displayName":"TARIQ JAMIL","userId":"15811585553781902842"}},"outputId":"22bad846-96df-4ae8-965d-7b9aa24f6015"},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"UoYicaYEeb8e"},"source":["Creating prompts using template"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1700927876862,"user":{"displayName":"TARIQ JAMIL","userId":"15811585553781902842"},"user_tz":-300},"id":"vozgLlNa8kVn","outputId":"bf292e5b-3c10-4185-8fb7-2b20b56e695d"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}],"source":["template='''\n","<|system|>\n","You are a proficient assistant who replies in a helpful manner.\n","If you don't know the reply, simply say 'Please refer to help desk'\n","Please keep you reply shorter and precise.\n","Only reply from the given context.\n","{context}\n","<|user|>\n","{question}\n","<|assistant|>'''.strip()\n","\n","prompt = PromptTemplate.from_template(template)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1700927876862,"user":{"displayName":"TARIQ JAMIL","userId":"15811585553781902842"},"user_tz":-300},"id":"pjwttFw4dxCS","outputId":"d3c6e8bb-7aed-4bfd-ff27-98255fe8d0c4"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["PromptTemplate(input_variables=['context', 'question'], template=\"<|system|>\\nYou are a proficient assistant who replies in a helpful manner.\\nIf you don't know the reply, simply say 'Please refer to help desk'\\nPlease keep you reply shorter and precise.\\nOnly reply from the given context.\\n{context}\\n<|user|>\\n{question}\\n<|assistant|>\")"]},"metadata":{},"execution_count":14}],"source":["prompt"]},{"cell_type":"code","source":["from langchain.embeddings import HuggingFaceBgeEmbeddings\n","\n","model_name = 'BAAI/bge-small-en-v1.5'\n","encode_kwargs = {'normalize_embeddings': True} # set True to compute cosine similarity\n","\n","embeddings = HuggingFaceBgeEmbeddings(\n","    model_name=model_name,\n","    model_kwargs={'device': 'cuda'},\n","    encode_kwargs=encode_kwargs\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"l-8W14VY9Sln","executionInfo":{"status":"ok","timestamp":1700927879072,"user_tz":-300,"elapsed":2222,"user":{"displayName":"TARIQ JAMIL","userId":"15811585553781902842"}},"outputId":"9a9737e0-0cee-43aa-d736-92e5bf067518"},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}]},{"cell_type":"markdown","source":["### Loading deep learning boom TJ's drive"],"metadata":{"id":"mEmv2LPSEorJ"}},{"cell_type":"code","source":["!gdown --fuzzy \"https://drive.google.com/file/d/1pE5b92Ucv5YyT24rG3vQZ6ZIdik2dRUg/view?usp=sharing\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":90},"id":"ddtyrRx-9Sq-","executionInfo":{"status":"ok","timestamp":1700927883260,"user_tz":-300,"elapsed":4192,"user":{"displayName":"TARIQ JAMIL","userId":"15811585553781902842"}},"outputId":"68dc72c3-221b-43b8-e70a-91a871bbc7ee"},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1pE5b92Ucv5YyT24rG3vQZ6ZIdik2dRUg\n","To: /content/Deep Learning with Python, 2nd Edition (Final Release) by Francois Chollet.pdf\n","\r  0% 0.00/15.1M [00:00<?, ?B/s]\r100% 15.1M/15.1M [00:00<00:00, 223MB/s]\n"]}]},{"cell_type":"markdown","source":["Reading the book"],"metadata":{"id":"bKKEDaXnEwlh"}},{"cell_type":"code","source":["loader = PyPDFDirectoryLoader('/content')\n","docs = loader.load()\n","len(docs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"83vUe0Ht9Soa","executionInfo":{"status":"ok","timestamp":1700927918221,"user_tz":-300,"elapsed":34966,"user":{"displayName":"TARIQ JAMIL","userId":"15811585553781902842"}},"outputId":"88c51e3f-4dd6-45ea-b672-5de55470a263"},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["504"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["Chunking"],"metadata":{"id":"SC8bJqplEzP1"}},{"cell_type":"code","source":["from langchain.text_splitter import RecursiveCharacterTextSplitter, TokenTextSplitter\n","\n","text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=64)\n","doc_chunks = text_splitter.split_documents(docs)\n","len(doc_chunks)"],"metadata":{"id":"pmzPL13fho-I","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1700927918222,"user_tz":-300,"elapsed":72,"user":{"displayName":"TARIQ JAMIL","userId":"15811585553781902842"}},"outputId":"2c5d0b74-4a16-49e1-ae25-118028729e50"},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["1364"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["verctor storage"],"metadata":{"id":"MR7i44AFFK_B"}},{"cell_type":"code","source":["from langchain.vectorstores import Chroma\n","\n","!rm -rf chromadb\n","persist_directory=\"./chromadb/\"\n","\n","vector_db = Chroma.from_documents(\n","    documents = doc_chunks, # text data that you want to embed and store\n","    embedding=embeddings, # used to convert the documents into embeddings\n","    persist_directory=persist_directory, # this tells Chroma where to store its data\n","    collection_name=\"Deep_Learning_Concepts\" #  gives a name to the collection of embeddings, which will be helpful for retrieving specific groups of embeddings later.\n",")\n","\n","vector_db.persist() # will make the database save any changes to the disk"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"eEbwqSod9SwP","executionInfo":{"status":"ok","timestamp":1700927935553,"user_tz":-300,"elapsed":17397,"user":{"displayName":"TARIQ JAMIL","userId":"15811585553781902842"}},"outputId":"c5aaa1cf-f826-4676-c279-8cc5904624aa"},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}]},{"cell_type":"markdown","source":["Getting vectordb again from persistance storage, I have deliberately used different name"],"metadata":{"id":"et5Qv5SgFunb"}},{"cell_type":"code","source":["vectordb = Chroma(persist_directory=persist_directory, embedding_function=embeddings)  # delibrately changed name to check it actually works\n","retriever=vectordb.as_retriever(search_kwargs={\"k\": 3})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"Q8uzwK5q9SzO","executionInfo":{"status":"ok","timestamp":1700927935554,"user_tz":-300,"elapsed":20,"user":{"displayName":"TARIQ JAMIL","userId":"15811585553781902842"}},"outputId":"f3cf7488-ebeb-4a01-dbdd-cd165649370b"},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["from langchain.memory import ConversationBufferWindowMemory\n","\n","memory = ConversationBufferWindowMemory(return_messages=True, k=5, memory_key='history')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"AI1Ym50_LgAg","executionInfo":{"status":"ok","timestamp":1700927935554,"user_tz":-300,"elapsed":19,"user":{"displayName":"TARIQ JAMIL","userId":"15811585553781902842"}},"outputId":"7af06f3d-d4e9-4e7f-b590-b0558d3eefe6"},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["template = \"\"\"\n","You are a proficient assistant who replies in a helpful manner.\n","If you don't know the reply, simply say 'Please refer to help desk'\n","Please keep you reply shorter and precise.\n","Only reply from the given context.\n","{context}\n","{chat_history}\n","Human:{question}\n","Assistant:\n","\"\"\"\n","\n","qa_chain_ws = RetrievalQAWithSourcesChain.from_chain_type(\n","    llm=llm,\n","    chain_type=\"stuff\",\n","    retriever=retriever,\n","    return_source_documents=True,\n","    memory=memory,\n","    chain_type_kwargs={\n","        \"prompt\": PromptTemplate(\n","            template=template,\n","            input_variables=[\"context\", \"question\", \"chat_history\"],\n","        ),\n","    },\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":441},"id":"FxLfyPT_KBJk","executionInfo":{"status":"error","timestamp":1700927936088,"user_tz":-300,"elapsed":552,"user":{"displayName":"TARIQ JAMIL","userId":"15811585553781902842"}},"outputId":"4abc8804-eb07-47d8-a9fb-fa256624e66e"},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"error","ename":"ValidationError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-dc90a5e5363e>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \"\"\"\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m qa_chain_ws = RetrievalQAWithSourcesChain.from_chain_type(\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mllm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mchain_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"stuff\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/qa_with_sources/base.py\u001b[0m in \u001b[0;36mfrom_chain_type\u001b[0;34m(cls, llm, chain_type, chain_type_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;34m\"\"\"Load chain from chain type.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0m_chain_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchain_type_kwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         combine_documents_chain = load_qa_with_sources_chain(\n\u001b[0m\u001b[1;32m     85\u001b[0m             \u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchain_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchain_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0m_chain_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/qa_with_sources/loading.py\u001b[0m in \u001b[0;36mload_qa_with_sources_chain\u001b[0;34m(llm, chain_type, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m         )\n\u001b[1;32m    181\u001b[0m     \u001b[0m_func\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLoadingCallable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchain_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/qa_with_sources/loading.py\u001b[0m in \u001b[0;36m_load_stuff_chain\u001b[0;34m(llm, prompt, document_prompt, document_variable_name, verbose, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m ) -> StuffDocumentsChain:\n\u001b[1;32m     61\u001b[0m     \u001b[0mllm_chain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLLMChain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     return StuffDocumentsChain(\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mllm_chain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm_chain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mdocument_variable_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdocument_variable_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/load/serializable.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lc_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydantic/v1/main.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__pydantic_self__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalidation_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mobject_setattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__pydantic_self__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__dict__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValidationError\u001b[0m: 1 validation error for StuffDocumentsChain\n__root__\n  document_variable_name summaries was not found in llm_chain input_variables: ['chat_history', 'context', 'question'] (type=value_error)"]}]},{"cell_type":"code","source":["qa_chain_ws('what is deep learning')"],"metadata":{"id":"vK1wIZZfKS0Z","executionInfo":{"status":"aborted","timestamp":1700927936088,"user_tz":-300,"elapsed":5,"user":{"displayName":"TARIQ JAMIL","userId":"15811585553781902842"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"KfG9AwJ6Kly7","executionInfo":{"status":"aborted","timestamp":1700927936088,"user_tz":-300,"elapsed":5,"user":{"displayName":"TARIQ JAMIL","userId":"15811585553781902842"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"aborted","timestamp":1700927936089,"user":{"displayName":"TARIQ JAMIL","userId":"15811585553781902842"},"user_tz":-300},"id":"5H01c22sMOuz"},"outputs":[],"source":["def chat(query):\n","    return qa_chain_ws(query)['answer']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4l82xckn-EVG","executionInfo":{"status":"aborted","timestamp":1700927936089,"user_tz":-300,"elapsed":6,"user":{"displayName":"TARIQ JAMIL","userId":"15811585553781902842"}}},"outputs":[],"source":["import gradio as gr\n","messages = []\n","\n","with gr.Blocks() as mychatbot:  # Blocks is a low-level API that allows\n","                                # you to create custom web applications\n","    chatbot = gr.Chatbot([], elem_id=\"NED SECC Chatbot V1.0\")\n","    #chatbot = gr.Chatbot(height=680)      # displays a chatbot\n","    question = gr.Textbox()     # for user to ask a question\n","    clear = gr.Button(\"Clear Conversation\")  # Clear button\n","    # function to clear the conversation\n","    def clear_messages():\n","        global messages, history\n","        messages = []    # reset the messages list\n","        memory.clear()\n","\n","    def chat(message, chat_history):\n","        global messages\n","        messages.append({\"role\": \"user\", \"content\": message})\n","        response = chat(message)\n","        print(response)\n","\n","        content = response#['choices'][0]['message']['content']\n","        messages.append({\"role\":\"assistant\", \"content\": content})\n","\n","        chat_history.append((message, content))\n","        return \"\", chat_history\n","\n","    # wire up the event handler for Submit button (when user press Enter)\n","    question.submit(fn = chat,\n","                    inputs = [question, chatbot],\n","                    outputs = [question, chatbot])\n","\n","    # wire up the event handler for the Clear Conversation button\n","    clear.click(fn = clear_messages,\n","                inputs = None,\n","                outputs = chatbot,\n","                queue = False)\n","\n","mychatbot.launch(debug=True, share=True)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"292d239d700a43c4959cbb8734c0fd33":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4ad380a5cc0c491cbbe7f082c6955aa5","IPY_MODEL_d2936272d6dc4cc68e0991dd0708c0bb","IPY_MODEL_e4b04c088d4547cf90f8139f5690b386"],"layout":"IPY_MODEL_7d67ea40bfd24a3ea40be7f346164808"}},"4ad380a5cc0c491cbbe7f082c6955aa5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_879d5bc6beed45819c2a8a9bead9efc2","placeholder":"​","style":"IPY_MODEL_93418527ad52431cb052cb41511f3f05","value":"Loading checkpoint shards: 100%"}},"d2936272d6dc4cc68e0991dd0708c0bb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_29469c80c2fb4de284abbc59efc797d3","max":8,"min":0,"orientation":"horizontal","style":"IPY_MODEL_91c36238ef0c42f6a9b37074f419d85c","value":8}},"e4b04c088d4547cf90f8139f5690b386":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a2b051e09bc94e7f90ffbca590b4a866","placeholder":"​","style":"IPY_MODEL_2f1c27d7ad694026808538d5af3cf254","value":" 8/8 [01:15&lt;00:00,  8.10s/it]"}},"7d67ea40bfd24a3ea40be7f346164808":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"879d5bc6beed45819c2a8a9bead9efc2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93418527ad52431cb052cb41511f3f05":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"29469c80c2fb4de284abbc59efc797d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91c36238ef0c42f6a9b37074f419d85c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a2b051e09bc94e7f90ffbca590b4a866":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f1c27d7ad694026808538d5af3cf254":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}