{"cells":[{"cell_type":"markdown","metadata":{"id":"Mc-n6O_h7dIP"},"source":["This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n","\n","**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n","\n","This notebook was generated for TensorFlow 2.6."]},{"cell_type":"markdown","metadata":{"id":"EJzFiuzp7dIR"},"source":["### Processing words as a sequence: The sequence model approach"]},{"cell_type":"markdown","metadata":{"id":"zKiLNU1_7dIR"},"source":["#### A first practical example"]},{"cell_type":"markdown","metadata":{"id":"osteYdvU7dIR"},"source":["**Downloading the data**"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HkB62J5r7dIR","executionInfo":{"status":"ok","timestamp":1700017651391,"user_tz":-300,"elapsed":19251,"user":{"displayName":"TARIQ JAMIL","userId":"15811585553781902842"}},"outputId":"976c6b5e-43cc-427d-ab42-91adf0ac82fb"},"outputs":[{"output_type":"stream","name":"stdout","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100 80.2M  100 80.2M    0     0  10.3M      0  0:00:07  0:00:07 --:--:-- 10.8M\n"]}],"source":["!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n","!tar -xf aclImdb_v1.tar.gz\n","!rm -r aclImdb/train/unsup"]},{"cell_type":"markdown","metadata":{"id":"KSCpO57S7dIS"},"source":["**Preparing the data**"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W_N8OeaD7dIS","executionInfo":{"status":"ok","timestamp":1700017661694,"user_tz":-300,"elapsed":10349,"user":{"displayName":"TARIQ JAMIL","userId":"15811585553781902842"}},"outputId":"fff6d7a5-3ee9-4079-ab90-8f5de38e144f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 20000 files belonging to 2 classes.\n","Found 5000 files belonging to 2 classes.\n","Found 25000 files belonging to 2 classes.\n"]}],"source":["import os, pathlib, shutil, random\n","from tensorflow import keras\n","batch_size = 32\n","base_dir = pathlib.Path(\"aclImdb\")\n","val_dir = base_dir / \"val\"\n","train_dir = base_dir / \"train\"\n","for category in (\"neg\", \"pos\"):\n","    os.makedirs(val_dir / category)\n","    files = os.listdir(train_dir / category)\n","    random.Random(1337).shuffle(files)\n","    num_val_samples = int(0.2 * len(files))\n","    val_files = files[-num_val_samples:]\n","    for fname in val_files:\n","        shutil.move(train_dir / category / fname,\n","                    val_dir / category / fname)\n","\n","train_ds = keras.utils.text_dataset_from_directory(\n","    \"aclImdb/train\", batch_size=batch_size\n",")\n","val_ds = keras.utils.text_dataset_from_directory(\n","    \"aclImdb/val\", batch_size=batch_size\n",")\n","test_ds = keras.utils.text_dataset_from_directory(\n","    \"aclImdb/test\", batch_size=batch_size\n",")\n","text_only_train_ds = train_ds.map(lambda x, y: x)"]},{"cell_type":"markdown","metadata":{"id":"6P-l-gCN7dIS"},"source":["**Preparing integer sequence datasets**"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"bGyeV9Mb7dIS","executionInfo":{"status":"ok","timestamp":1700017667388,"user_tz":-300,"elapsed":5744,"user":{"displayName":"TARIQ JAMIL","userId":"15811585553781902842"}}},"outputs":[],"source":["from tensorflow.keras import layers\n","\n","max_length = 600\n","max_tokens = 20000\n","text_vectorization = layers.TextVectorization(\n","    max_tokens=max_tokens,\n","    output_mode=\"int\",\n","    output_sequence_length=max_length,\n",")\n","text_vectorization.adapt(text_only_train_ds)\n","\n","int_train_ds = train_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)\n","int_val_ds = val_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)\n","int_test_ds = test_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls=4)"]},{"cell_type":"markdown","metadata":{"id":"Lco4B4SJ7dIT"},"source":["**A sequence model built on one-hot encoded vector sequences**"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iKH-2P9e7dIT","executionInfo":{"status":"ok","timestamp":1700017667960,"user_tz":-300,"elapsed":618,"user":{"displayName":"TARIQ JAMIL","userId":"15811585553781902842"}},"outputId":"8ccfc216-4e72-4552-fe62-4e236d5547bf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, None)]            0         \n","                                                                 \n"," tf.one_hot (TFOpLambda)     (None, None, 20000)       0         \n","                                                                 \n"," bidirectional (Bidirection  (None, 64)                5128448   \n"," al)                                                             \n","                                                                 \n"," dropout (Dropout)           (None, 64)                0         \n","                                                                 \n"," dense (Dense)               (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 5128513 (19.56 MB)\n","Trainable params: 5128513 (19.56 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["import tensorflow as tf\n","inputs = keras.Input(shape=(None,), dtype=\"int64\")\n","embedded = tf.one_hot(inputs, depth=max_tokens)\n","x = layers.Bidirectional(layers.LSTM(32))(embedded)\n","x = layers.Dropout(0.5)(x)\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","model = keras.Model(inputs, outputs)\n","model.compile(optimizer=\"rmsprop\",\n","              loss=\"binary_crossentropy\",\n","              metrics=[\"accuracy\"])\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"hqx51w1R7dIT"},"source":["**Training a first basic sequence model**"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dtz16trc7dIT","executionInfo":{"status":"ok","timestamp":1700019681248,"user_tz":-300,"elapsed":2013304,"user":{"displayName":"TARIQ JAMIL","userId":"15811585553781902842"}},"outputId":"8eede095-95fc-4604-e718-dbdcdef16c14"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","625/625 [==============================] - 173s 261ms/step - loss: 0.5478 - accuracy: 0.7222 - val_loss: 0.4025 - val_accuracy: 0.8336\n","Epoch 2/10\n","625/625 [==============================] - 167s 267ms/step - loss: 0.3588 - accuracy: 0.8691 - val_loss: 0.3024 - val_accuracy: 0.8834\n","Epoch 3/10\n","625/625 [==============================] - 163s 261ms/step - loss: 0.2940 - accuracy: 0.8986 - val_loss: 0.3005 - val_accuracy: 0.8780\n","Epoch 4/10\n","625/625 [==============================] - 163s 260ms/step - loss: 0.2661 - accuracy: 0.9093 - val_loss: 0.2940 - val_accuracy: 0.8952\n","Epoch 5/10\n","625/625 [==============================] - 166s 266ms/step - loss: 0.2285 - accuracy: 0.9216 - val_loss: 0.2904 - val_accuracy: 0.8896\n","Epoch 6/10\n","625/625 [==============================] - 153s 245ms/step - loss: 0.2082 - accuracy: 0.9315 - val_loss: 0.2982 - val_accuracy: 0.8936\n","Epoch 7/10\n","625/625 [==============================] - 153s 245ms/step - loss: 0.1919 - accuracy: 0.9362 - val_loss: 0.3016 - val_accuracy: 0.8904\n","Epoch 8/10\n","625/625 [==============================] - 156s 249ms/step - loss: 0.1707 - accuracy: 0.9446 - val_loss: 0.3613 - val_accuracy: 0.8960\n","Epoch 9/10\n","625/625 [==============================] - 156s 249ms/step - loss: 0.1562 - accuracy: 0.9510 - val_loss: 0.3098 - val_accuracy: 0.8880\n","Epoch 10/10\n","625/625 [==============================] - 156s 249ms/step - loss: 0.1378 - accuracy: 0.9566 - val_loss: 0.3619 - val_accuracy: 0.8950\n","782/782 [==============================] - 94s 119ms/step - loss: 0.3156 - accuracy: 0.8787\n","Test acc: 0.879\n"]}],"source":["callbacks = [\n","    keras.callbacks.ModelCheckpoint(\"one_hot_bidir_lstm.tf\",\n","                                    save_best_only=True)\n","]\n","model.fit(int_train_ds, validation_data=int_val_ds, epochs=10, callbacks=callbacks)\n","model = keras.models.load_model(\"one_hot_bidir_lstm.tf\")\n","print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"]},{"cell_type":"markdown","metadata":{"id":"84PnR1kd7dIT"},"source":["#### Understanding word embeddings"]},{"cell_type":"markdown","metadata":{"id":"Vxd4dOGp7dIT"},"source":["#### Learning word embeddings with the Embedding layer"]},{"cell_type":"markdown","metadata":{"id":"oRJ5-Utw7dIU"},"source":["**Instantiating an `Embedding` layer**"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"9T2ijwvn7dIU","executionInfo":{"status":"ok","timestamp":1700019681249,"user_tz":-300,"elapsed":53,"user":{"displayName":"TARIQ JAMIL","userId":"15811585553781902842"}}},"outputs":[],"source":["embedding_layer = layers.Embedding(input_dim=max_tokens, output_dim=256)"]},{"cell_type":"markdown","metadata":{"id":"kapcsOa07dIU"},"source":["**Model that uses an `Embedding` layer trained from scratch**"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lgttNDzY7dIU","executionInfo":{"status":"ok","timestamp":1700020139788,"user_tz":-300,"elapsed":458548,"user":{"displayName":"TARIQ JAMIL","userId":"15811585553781902842"}},"outputId":"c8a31bb2-80f6-44bb-97fb-2b8db2fa12b1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, None)]            0         \n","                                                                 \n"," embedding_1 (Embedding)     (None, None, 256)         5120000   \n","                                                                 \n"," bidirectional_1 (Bidirecti  (None, 64)                73984     \n"," onal)                                                           \n","                                                                 \n"," dropout_1 (Dropout)         (None, 64)                0         \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 5194049 (19.81 MB)\n","Trainable params: 5194049 (19.81 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/10\n","625/625 [==============================] - 65s 97ms/step - loss: 0.5186 - accuracy: 0.7438 - val_loss: 0.6601 - val_accuracy: 0.7270\n","Epoch 2/10\n","625/625 [==============================] - 47s 76ms/step - loss: 0.3570 - accuracy: 0.8644 - val_loss: 0.3241 - val_accuracy: 0.8770\n","Epoch 3/10\n","625/625 [==============================] - 41s 66ms/step - loss: 0.2942 - accuracy: 0.8946 - val_loss: 0.3139 - val_accuracy: 0.8724\n","Epoch 4/10\n","625/625 [==============================] - 31s 50ms/step - loss: 0.2463 - accuracy: 0.9151 - val_loss: 0.3294 - val_accuracy: 0.8782\n","Epoch 5/10\n","625/625 [==============================] - 29s 47ms/step - loss: 0.2230 - accuracy: 0.9224 - val_loss: 0.3314 - val_accuracy: 0.8726\n","Epoch 6/10\n","625/625 [==============================] - 27s 43ms/step - loss: 0.1847 - accuracy: 0.9395 - val_loss: 0.3763 - val_accuracy: 0.8840\n","Epoch 7/10\n","625/625 [==============================] - 27s 43ms/step - loss: 0.1610 - accuracy: 0.9481 - val_loss: 0.3856 - val_accuracy: 0.8768\n","Epoch 8/10\n","625/625 [==============================] - 29s 46ms/step - loss: 0.1431 - accuracy: 0.9558 - val_loss: 0.4350 - val_accuracy: 0.8714\n","Epoch 9/10\n","625/625 [==============================] - 26s 42ms/step - loss: 0.1131 - accuracy: 0.9643 - val_loss: 0.5013 - val_accuracy: 0.8690\n","Epoch 10/10\n","625/625 [==============================] - 26s 41ms/step - loss: 0.1098 - accuracy: 0.9672 - val_loss: 0.4145 - val_accuracy: 0.8744\n","782/782 [==============================] - 14s 17ms/step - loss: 0.3460 - accuracy: 0.8582\n","Test acc: 0.858\n"]}],"source":["inputs = keras.Input(shape=(None,), dtype=\"int64\")\n","embedded = layers.Embedding(input_dim=max_tokens, output_dim=256)(inputs)\n","x = layers.Bidirectional(layers.LSTM(32))(embedded)\n","x = layers.Dropout(0.5)(x)\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","model = keras.Model(inputs, outputs)\n","model.compile(optimizer=\"rmsprop\",\n","              loss=\"binary_crossentropy\",\n","              metrics=[\"accuracy\"])\n","model.summary()\n","\n","callbacks = [\n","    keras.callbacks.ModelCheckpoint(\"embeddings_bidir_gru.tf\",\n","                                    save_best_only=True)\n","]\n","model.fit(int_train_ds, validation_data=int_val_ds, epochs=10, callbacks=callbacks)\n","model = keras.models.load_model(\"embeddings_bidir_gru.tf\")\n","print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"]},{"cell_type":"markdown","metadata":{"id":"0uyZ8yHh7dIU"},"source":["#### Understanding padding and masking"]},{"cell_type":"markdown","metadata":{"id":"4QvkxdqJ7dIU"},"source":["**Using an `Embedding` layer with masking enabled**"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ms33_E7j7dIU","executionInfo":{"status":"ok","timestamp":1700020672615,"user_tz":-300,"elapsed":532879,"user":{"displayName":"TARIQ JAMIL","userId":"15811585553781902842"}},"outputId":"b50fd5ab-a549-4fca-87ec-8cab72c6f109"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_3 (InputLayer)        [(None, None)]            0         \n","                                                                 \n"," embedding_2 (Embedding)     (None, None, 256)         5120000   \n","                                                                 \n"," bidirectional_2 (Bidirecti  (None, 64)                73984     \n"," onal)                                                           \n","                                                                 \n"," dropout_2 (Dropout)         (None, 64)                0         \n","                                                                 \n"," dense_2 (Dense)             (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 5194049 (19.81 MB)\n","Trainable params: 5194049 (19.81 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/10\n","625/625 [==============================] - 85s 122ms/step - loss: 0.4788 - accuracy: 0.7617 - val_loss: 0.3636 - val_accuracy: 0.8400\n","Epoch 2/10\n","625/625 [==============================] - 57s 91ms/step - loss: 0.2962 - accuracy: 0.8804 - val_loss: 0.2848 - val_accuracy: 0.8840\n","Epoch 3/10\n","625/625 [==============================] - 34s 55ms/step - loss: 0.2260 - accuracy: 0.9138 - val_loss: 0.2912 - val_accuracy: 0.8850\n","Epoch 4/10\n","625/625 [==============================] - 34s 54ms/step - loss: 0.1757 - accuracy: 0.9348 - val_loss: 0.3520 - val_accuracy: 0.8726\n","Epoch 5/10\n","625/625 [==============================] - 32s 52ms/step - loss: 0.1324 - accuracy: 0.9524 - val_loss: 0.3546 - val_accuracy: 0.8814\n","Epoch 6/10\n","625/625 [==============================] - 30s 48ms/step - loss: 0.1044 - accuracy: 0.9644 - val_loss: 0.4049 - val_accuracy: 0.8774\n","Epoch 7/10\n","625/625 [==============================] - 30s 49ms/step - loss: 0.0787 - accuracy: 0.9738 - val_loss: 0.4240 - val_accuracy: 0.8822\n","Epoch 8/10\n","625/625 [==============================] - 32s 51ms/step - loss: 0.0634 - accuracy: 0.9790 - val_loss: 0.4318 - val_accuracy: 0.8868\n","Epoch 9/10\n","625/625 [==============================] - 30s 48ms/step - loss: 0.0499 - accuracy: 0.9837 - val_loss: 0.4844 - val_accuracy: 0.8816\n","Epoch 10/10\n","625/625 [==============================] - 30s 48ms/step - loss: 0.0383 - accuracy: 0.9875 - val_loss: 0.5483 - val_accuracy: 0.8778\n","782/782 [==============================] - 17s 19ms/step - loss: 0.3143 - accuracy: 0.8712\n","Test acc: 0.871\n"]}],"source":["inputs = keras.Input(shape=(None,), dtype=\"int64\")\n","embedded = layers.Embedding(\n","    input_dim=max_tokens, output_dim=256, mask_zero=True)(inputs)\n","x = layers.Bidirectional(layers.LSTM(32))(embedded)\n","x = layers.Dropout(0.5)(x)\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","model = keras.Model(inputs, outputs)\n","model.compile(optimizer=\"rmsprop\",\n","              loss=\"binary_crossentropy\",\n","              metrics=[\"accuracy\"])\n","model.summary()\n","\n","callbacks = [\n","    keras.callbacks.ModelCheckpoint(\"embeddings_bidir_gru_with_masking.tf\",\n","                                    save_best_only=True)\n","]\n","model.fit(int_train_ds, validation_data=int_val_ds, epochs=10, callbacks=callbacks)\n","model = keras.models.load_model(\"embeddings_bidir_gru_with_masking.tf\")\n","print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"]},{"cell_type":"markdown","metadata":{"id":"yEcxpAbE7dIU"},"source":["#### Using pretrained word embeddings"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BU8J0hyR7dIU","executionInfo":{"status":"ok","timestamp":1700020867619,"user_tz":-300,"elapsed":195024,"user":{"displayName":"TARIQ JAMIL","userId":"15811585553781902842"}},"outputId":"5afc29a8-ee25-4bd2-e039-25f7220af054"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-11-15 03:57:51--  http://nlp.stanford.edu/data/glove.6B.zip\n","Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n","--2023-11-15 03:57:51--  https://nlp.stanford.edu/data/glove.6B.zip\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n","--2023-11-15 03:57:51--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n","Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n","Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 862182613 (822M) [application/zip]\n","Saving to: ‘glove.6B.zip’\n","\n","glove.6B.zip        100%[===================>] 822.24M  5.01MB/s    in 2m 39s  \n","\n","2023-11-15 04:00:31 (5.16 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n","\n"]}],"source":["!wget http://nlp.stanford.edu/data/glove.6B.zip\n","!unzip -q glove.6B.zip"]},{"cell_type":"markdown","metadata":{"id":"QSZqn70E7dIV"},"source":["**Parsing the GloVe word-embeddings file**"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Br2_9ea7dIV","executionInfo":{"status":"ok","timestamp":1700020874487,"user_tz":-300,"elapsed":6921,"user":{"displayName":"TARIQ JAMIL","userId":"15811585553781902842"}},"outputId":"8c5dd842-881c-4d39-9197-6aca505de63f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 400000 word vectors.\n"]}],"source":["import numpy as np\n","path_to_glove_file = \"glove.6B.100d.txt\"\n","\n","embeddings_index = {}\n","with open(path_to_glove_file) as f:\n","    for line in f:\n","        word, coefs = line.split(maxsplit=1)\n","        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n","        embeddings_index[word] = coefs\n","\n","print(f\"Found {len(embeddings_index)} word vectors.\")"]},{"cell_type":"markdown","metadata":{"id":"p_PVADJC7dIV"},"source":["**Preparing the GloVe word-embeddings matrix**"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"xeuw6RSa7dIV","executionInfo":{"status":"ok","timestamp":1700020874488,"user_tz":-300,"elapsed":62,"user":{"displayName":"TARIQ JAMIL","userId":"15811585553781902842"}}},"outputs":[],"source":["embedding_dim = 100\n","\n","vocabulary = text_vectorization.get_vocabulary()\n","word_index = dict(zip(vocabulary, range(len(vocabulary))))\n","\n","embedding_matrix = np.zeros((max_tokens, embedding_dim))\n","for word, i in word_index.items():\n","    if i < max_tokens:\n","        embedding_vector = embeddings_index.get(word)\n","    if embedding_vector is not None:\n","        embedding_matrix[i] = embedding_vector"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"dqbzEeGf7dIV","executionInfo":{"status":"ok","timestamp":1700020874489,"user_tz":-300,"elapsed":60,"user":{"displayName":"TARIQ JAMIL","userId":"15811585553781902842"}}},"outputs":[],"source":["embedding_layer = layers.Embedding(\n","    max_tokens,\n","    embedding_dim,\n","    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n","    trainable=False,\n","    mask_zero=True,\n",")"]},{"cell_type":"markdown","metadata":{"id":"tK7pqGeS7dIV"},"source":["**Model that uses a pretrained Embedding layer**"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5L6-OWdX7dIV","executionInfo":{"status":"ok","timestamp":1700021603444,"user_tz":-300,"elapsed":729014,"user":{"displayName":"TARIQ JAMIL","userId":"15811585553781902842"}},"outputId":"d0ce3428-cc17-403f-8d86-7e70255620fa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_4 (InputLayer)        [(None, None)]            0         \n","                                                                 \n"," embedding_3 (Embedding)     (None, None, 100)         2000000   \n","                                                                 \n"," bidirectional_3 (Bidirecti  (None, 64)                34048     \n"," onal)                                                           \n","                                                                 \n"," dropout_3 (Dropout)         (None, 64)                0         \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 2034113 (7.76 MB)\n","Trainable params: 34113 (133.25 KB)\n","Non-trainable params: 2000000 (7.63 MB)\n","_________________________________________________________________\n","Epoch 1/10\n","625/625 [==============================] - 82s 115ms/step - loss: 0.5744 - accuracy: 0.6936 - val_loss: 0.4906 - val_accuracy: 0.7654\n","Epoch 2/10\n","625/625 [==============================] - 60s 96ms/step - loss: 0.4611 - accuracy: 0.7875 - val_loss: 0.4336 - val_accuracy: 0.7948\n","Epoch 3/10\n","625/625 [==============================] - 63s 101ms/step - loss: 0.4078 - accuracy: 0.8195 - val_loss: 0.3700 - val_accuracy: 0.8390\n","Epoch 4/10\n","625/625 [==============================] - 55s 89ms/step - loss: 0.3773 - accuracy: 0.8371 - val_loss: 0.3488 - val_accuracy: 0.8506\n","Epoch 5/10\n","625/625 [==============================] - 55s 89ms/step - loss: 0.3479 - accuracy: 0.8515 - val_loss: 0.3355 - val_accuracy: 0.8568\n","Epoch 6/10\n","625/625 [==============================] - 27s 44ms/step - loss: 0.3255 - accuracy: 0.8623 - val_loss: 0.3648 - val_accuracy: 0.8360\n","Epoch 7/10\n","625/625 [==============================] - 59s 94ms/step - loss: 0.3067 - accuracy: 0.8744 - val_loss: 0.3129 - val_accuracy: 0.8704\n","Epoch 8/10\n","625/625 [==============================] - 58s 93ms/step - loss: 0.2890 - accuracy: 0.8812 - val_loss: 0.3021 - val_accuracy: 0.8754\n","Epoch 9/10\n","625/625 [==============================] - 27s 43ms/step - loss: 0.2755 - accuracy: 0.8870 - val_loss: 0.3742 - val_accuracy: 0.8384\n","Epoch 10/10\n","625/625 [==============================] - 56s 90ms/step - loss: 0.2610 - accuracy: 0.8946 - val_loss: 0.2938 - val_accuracy: 0.8802\n","782/782 [==============================] - 17s 18ms/step - loss: 0.2933 - accuracy: 0.8739\n","Test acc: 0.874\n"]}],"source":["inputs = keras.Input(shape=(None,), dtype=\"int64\")\n","embedded = embedding_layer(inputs)\n","x = layers.Bidirectional(layers.LSTM(32))(embedded)\n","x = layers.Dropout(0.5)(x)\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","model = keras.Model(inputs, outputs)\n","model.compile(optimizer=\"rmsprop\",\n","              loss=\"binary_crossentropy\",\n","              metrics=[\"accuracy\"])\n","model.summary()\n","\n","callbacks = [\n","    keras.callbacks.ModelCheckpoint(\"glove_embeddings_sequence_model.tf\",\n","                                    save_best_only=True)\n","]\n","model.fit(int_train_ds, validation_data=int_val_ds, epochs=10, callbacks=callbacks)\n","model = keras.models.load_model(\"glove_embeddings_sequence_model.tf\")\n","print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"]}],"metadata":{"colab":{"provenance":[],"toc_visible":true,"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}